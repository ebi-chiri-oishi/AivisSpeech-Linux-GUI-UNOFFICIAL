/* tslint:disable */
/* eslint-disable */
/**
 * AivisSpeech Engine
 * AivisSpeech の音声合成エンジンです。
 *
 * The version of the OpenAPI document: latest
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


import * as runtime from '../runtime';
import type {
  AccentPhrase,
  AivmInfo,
  AudioQuery,
  BodySingFrameF0SingFrameF0Post,
  BodySingFrameVolumeSingFrameVolumePost,
  CorsPolicyMode,
  EngineManifest,
  FrameAudioQuery,
  HTTPValidationError,
  MorphableTargetInfo,
  ParseKanaBadRequest,
  Preset,
  ResponseGetUserDictWordsUserDictGet,
  Score,
  Speaker,
  SpeakerInfo,
  SupportedDevicesInfo,
  WordTypes,
} from '../models/index';
import {
    AccentPhraseFromJSON,
    AccentPhraseToJSON,
    AivmInfoFromJSON,
    AivmInfoToJSON,
    AudioQueryFromJSON,
    AudioQueryToJSON,
    BodySingFrameF0SingFrameF0PostFromJSON,
    BodySingFrameF0SingFrameF0PostToJSON,
    BodySingFrameVolumeSingFrameVolumePostFromJSON,
    BodySingFrameVolumeSingFrameVolumePostToJSON,
    CorsPolicyModeFromJSON,
    CorsPolicyModeToJSON,
    EngineManifestFromJSON,
    EngineManifestToJSON,
    FrameAudioQueryFromJSON,
    FrameAudioQueryToJSON,
    HTTPValidationErrorFromJSON,
    HTTPValidationErrorToJSON,
    MorphableTargetInfoFromJSON,
    MorphableTargetInfoToJSON,
    ParseKanaBadRequestFromJSON,
    ParseKanaBadRequestToJSON,
    PresetFromJSON,
    PresetToJSON,
    ResponseGetUserDictWordsUserDictGetFromJSON,
    ResponseGetUserDictWordsUserDictGetToJSON,
    ScoreFromJSON,
    ScoreToJSON,
    SpeakerFromJSON,
    SpeakerToJSON,
    SpeakerInfoFromJSON,
    SpeakerInfoToJSON,
    SupportedDevicesInfoFromJSON,
    SupportedDevicesInfoToJSON,
    WordTypesFromJSON,
    WordTypesToJSON,
} from '../models/index';

export interface AccentPhrasesRequest {
    text: string;
    speaker: number;
    isKana?: boolean;
    coreVersion?: string;
}

export interface AddPresetRequest {
    preset: Preset;
}

export interface AddUserDictWordRequest {
    surface: Array<string>;
    pronunciation: Array<string>;
    accentType: Array<number>;
    wordType?: WordTypes;
    priority?: number;
}

export interface AudioQueryRequest {
    text: string;
    speaker: number;
    coreVersion?: string;
}

export interface AudioQueryFromPresetRequest {
    text: string;
    presetId: number;
    coreVersion?: string;
}

export interface CancellableSynthesisRequest {
    speaker: number;
    audioQuery: AudioQuery;
    coreVersion?: string;
}

export interface ConnectWavesRequest {
    requestBody: Array<string>;
}

export interface DeletePresetRequest {
    id: number;
}

export interface DeleteUserDictWordRequest {
    wordUuid: string;
}

export interface FrameSynthesisRequest {
    speaker: number;
    frameAudioQuery: FrameAudioQuery;
    coreVersion?: string;
}

export interface GetAivmInfoRequest {
    aivmUuid: string;
}

export interface GetUserDictWordsRequest {
    enableCompoundAccent?: boolean;
}

export interface ImportUserDictWordsRequest {
    override: boolean;
    requestBody: { [key: string]: ResponseGetUserDictWordsUserDictGet; } | null;
}

export interface InitializeSpeakerRequest {
    speaker: number;
    skipReinit?: boolean;
    coreVersion?: string;
}

export interface InstallModelRequest {
    file?: Blob | null;
    url?: string | null;
}

export interface IsInitializedSpeakerRequest {
    speaker: number;
    coreVersion?: string;
}

export interface LoadModelRequest {
    aivmUuid: string;
}

export interface MoraDataRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
    coreVersion?: string;
}

export interface MoraLengthRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
    coreVersion?: string;
}

export interface MoraPitchRequest {
    speaker: number;
    accentPhrase: Array<AccentPhrase>;
    coreVersion?: string;
}

export interface MorphableTargetsRequest {
    requestBody: Array<number>;
    coreVersion?: string;
}

export interface MultiSynthesisRequest {
    speaker: number;
    audioQuery: Array<AudioQuery>;
    coreVersion?: string;
}

export interface SettingPostRequest {
    corsPolicyMode: CorsPolicyMode;
    allowOrigin?: string;
}

export interface SingFrameAudioQueryRequest {
    speaker: number;
    score: Score;
    coreVersion?: string;
}

export interface SingFrameF0Request {
    speaker: number;
    bodySingFrameF0SingFrameF0Post: BodySingFrameF0SingFrameF0Post;
    coreVersion?: string;
}

export interface SingFrameVolumeRequest {
    speaker: number;
    bodySingFrameVolumeSingFrameVolumePost: BodySingFrameVolumeSingFrameVolumePost;
    coreVersion?: string;
}

export interface SingerInfoRequest {
    speakerUuid: string;
    resourceFormat?: SingerInfoResourceFormatEnum;
    coreVersion?: string;
}

export interface SingersRequest {
    coreVersion?: string;
}

export interface SpeakerInfoRequest {
    speakerUuid: string;
    resourceFormat?: SpeakerInfoResourceFormatEnum;
    coreVersion?: string;
}

export interface SpeakersRequest {
    coreVersion?: string;
}

export interface SupportedDevicesRequest {
    coreVersion?: string;
}

export interface SynthesisRequest {
    speaker: number;
    audioQuery: AudioQuery;
    enableInterrogativeUpspeak?: boolean;
    coreVersion?: string;
}

export interface SynthesisMorphingRequest {
    baseSpeaker: number;
    targetSpeaker: number;
    morphRate: number;
    audioQuery: AudioQuery;
    coreVersion?: string;
}

export interface UninstallModelRequest {
    aivmUuid: string;
}

export interface UnloadModelRequest {
    aivmUuid: string;
}

export interface UpdateModelRequest {
    aivmUuid: string;
}

export interface UpdatePresetRequest {
    preset: Preset;
}

export interface UpdateUserDictWordRequest {
    wordUuid: string;
    surface: Array<string>;
    pronunciation: Array<string>;
    accentType: Array<number>;
    wordType?: WordTypes;
    priority?: number;
}

export interface ValidateKanaRequest {
    text: string;
}

/**
 * DefaultApi - interface
 * 
 * @export
 * @interface DefaultApiInterface
 */
export interface DefaultApiInterface {
    /**
     * テキストからアクセント句を得ます。<br> is_kanaが`true`のとき、テキストは次の AquesTalk 風記法で解釈されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。 * アクセント句末に`？`(全角)を入れることにより疑問文の発音ができる。
     * @summary テキストからアクセント句を得る
     * @param {string} text 
     * @param {number} speaker 
     * @param {boolean} [isKana] 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    accentPhrasesRaw(requestParameters: AccentPhrasesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>>;

    /**
     * テキストからアクセント句を得ます。<br> is_kanaが`true`のとき、テキストは次の AquesTalk 風記法で解釈されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。 * アクセント句末に`？`(全角)を入れることにより疑問文の発音ができる。
     * テキストからアクセント句を得る
     */
    accentPhrases(requestParameters: AccentPhrasesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>>;

    /**
     * 新しいプリセットを追加します。
     * @summary 新しいプリセットを追加する
     * @param {Preset} preset 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    addPresetRaw(requestParameters: AddPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<number>>;

    /**
     * 新しいプリセットを追加します。
     * 新しいプリセットを追加する
     */
    addPreset(requestParameters: AddPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<number>;

    /**
     * ユーザー辞書に単語を追加します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * @summary ユーザー辞書に単語を追加する
     * @param {Array<string>} surface 単語の表層形
     * @param {Array<string>} pronunciation 単語の発音（カタカナ）
     * @param {Array<number>} accentType 東京式アクセントにおけるアクセント型&lt;br&gt;音高が下がる直前のモーラのインデックスを 1-indexed で指定します。0 は平板型を意味します。&lt;br&gt;例として、&#x60;surface: [\&quot;新田\&quot;, \&quot;真剣佑\&quot;], pronunciation: [\&quot;あらた\&quot;, \&quot;まっけんゆう\&quot;]&#x60; のとき、&#x60;accent_type: [1, 3]&#x60; (新田 → 頭高型, 真剣佑 → 中高型) のように指定します。
     * @param {WordTypes} [wordType] 単語の品詞&lt;br&gt;固有名詞 / 地名 / 組織・施設名 / 人名 / 人名 (姓) / 人名 (名) / 普通名詞 / 動詞 / 形容詞 / 語尾 のいずれかを指定します。&lt;br&gt;未指定時は &#x60;固有名詞&#x60; が設定されます。
     * @param {number} [priority] 単語の優先度 (1~9 の範囲を推奨)&lt;br&gt;数値が大きいほど、辞書適用時に優先して利用されます。&lt;br&gt;未指定時は &#x60;5&#x60; が設定されます。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    addUserDictWordRaw(requestParameters: AddUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>>;

    /**
     * ユーザー辞書に単語を追加します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に単語を追加する
     */
    addUserDictWord(requestParameters: AddUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string>;

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * @summary 音声合成用のクエリを作成する
     * @param {string} text 
     * @param {number} speaker 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    audioQueryRaw(requestParameters: AudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AudioQuery>>;

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリを作成する
     */
    audioQuery(requestParameters: AudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AudioQuery>;

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * @summary 音声合成用のクエリをプリセットを用いて作成する
     * @param {string} text 
     * @param {number} presetId 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    audioQueryFromPresetRaw(requestParameters: AudioQueryFromPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AudioQuery>>;

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリをプリセットを用いて作成する
     */
    audioQueryFromPreset(requestParameters: AudioQueryFromPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AudioQuery>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {number} speaker 
     * @param {AudioQuery} audioQuery 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    cancellableSynthesisRaw(requestParameters: CancellableSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    cancellableSynthesis(requestParameters: CancellableSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * Base64 エンコードされた WAV データを一つに結合し、WAV ファイルで返します。
     * @summary Base64 エンコードされた複数の WAV データを一つに結合する
     * @param {Array<string>} requestBody 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    connectWavesRaw(requestParameters: ConnectWavesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * Base64 エンコードされた WAV データを一つに結合し、WAV ファイルで返します。
     * Base64 エンコードされた複数の WAV データを一つに結合する
     */
    connectWaves(requestParameters: ConnectWavesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * 利用可能なコアのバージョン一覧を取得します。
     * @summary Core Versions
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    coreVersionsRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<string>>>;

    /**
     * 利用可能なコアのバージョン一覧を取得します。
     * Core Versions
     */
    coreVersions(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<string>>;

    /**
     * 既存のプリセットを削除します。
     * @summary 既存のプリセットを削除する
     * @param {number} id 削除するプリセットのプリセットID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    deletePresetRaw(requestParameters: DeletePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 既存のプリセットを削除します。
     * 既存のプリセットを削除する
     */
    deletePreset(requestParameters: DeletePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * ユーザー辞書に登録されている単語を削除します。
     * @summary ユーザー辞書に登録されている単語を削除する
     * @param {string} wordUuid 削除する単語の UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    deleteUserDictWordRaw(requestParameters: DeleteUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * ユーザー辞書に登録されている単語を削除します。
     * ユーザー辞書に登録されている単語を削除する
     */
    deleteUserDictWord(requestParameters: DeleteUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * エンジンマニフェストを取得します。
     * @summary Engine Manifest
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    engineManifestRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<EngineManifest>>;

    /**
     * エンジンマニフェストを取得します。
     * Engine Manifest
     */
    engineManifest(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<EngineManifest>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {number} speaker 
     * @param {FrameAudioQuery} frameAudioQuery 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    frameSynthesisRaw(requestParameters: FrameSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    frameSynthesis(requestParameters: FrameSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * 指定された音声合成モデルの情報を取得します。
     * @summary 指定された音声合成モデルの情報を取得する
     * @param {string} aivmUuid 音声合成モデルの UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    getAivmInfoRaw(requestParameters: GetAivmInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AivmInfo>>;

    /**
     * 指定された音声合成モデルの情報を取得します。
     * 指定された音声合成モデルの情報を取得する
     */
    getAivmInfo(requestParameters: GetAivmInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AivmInfo>;

    /**
     * インストール済みのすべての音声合成モデルの情報を返します。
     * @summary インストール済みのすべての音声合成モデルの情報を取得する
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    getInstalledAivmInfosRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<{ [key: string]: AivmInfo; }>>;

    /**
     * インストール済みのすべての音声合成モデルの情報を返します。
     * インストール済みのすべての音声合成モデルの情報を取得する
     */
    getInstalledAivmInfos(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<{ [key: string]: AivmInfo; }>;

    /**
     * ポータルページを返します。
     * @summary Get Portal Page
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    getPortalPageRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>>;

    /**
     * ポータルページを返します。
     * Get Portal Page
     */
    getPortalPage(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string>;

    /**
     * エンジンが保持しているプリセットの設定を返します。
     * @summary エンジンが保持しているプリセットの設定を取得する
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    getPresetsRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Preset>>>;

    /**
     * エンジンが保持しているプリセットの設定を返します。
     * エンジンが保持しているプリセットの設定を取得する
     */
    getPresets(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Preset>>;

    /**
     * ユーザー辞書に登録されている単語の一覧を返します。<br> 複合語アクセントのサポートを有効にするか次第で、返されるデータ型が変化します。<br> デフォルトでは、従来の API と互換性のある `UserDictWordForCompat` を返します。<br> `?enable_compound_accent=true` を指定すると、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` を返します。
     * @summary ユーザー辞書に登録されている単語の一覧を取得する
     * @param {boolean} [enableCompoundAccent] 複数のアクセント句を持つ単語の扱いを指定する&lt;br&gt;false の場合は API 互換性のため、最初のアクセント句の情報のみを返します。&lt;br&gt;未指定時は &#x60;false&#x60; が設定されます。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    getUserDictWordsRaw(requestParameters: GetUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<{ [key: string]: ResponseGetUserDictWordsUserDictGet; }>>;

    /**
     * ユーザー辞書に登録されている単語の一覧を返します。<br> 複合語アクセントのサポートを有効にするか次第で、返されるデータ型が変化します。<br> デフォルトでは、従来の API と互換性のある `UserDictWordForCompat` を返します。<br> `?enable_compound_accent=true` を指定すると、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` を返します。
     * ユーザー辞書に登録されている単語の一覧を取得する
     */
    getUserDictWords(requestParameters: GetUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<{ [key: string]: ResponseGetUserDictWordsUserDictGet; }>;

    /**
     * 指定されたユーザー辞書をインポートします。<br> 従来の API と互換性のある `UserDictWordForCompat` と、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` の両方の型に対応しています。<br> `?override=true` を指定すると、UUID が重複したエントリはインポートしたデータで上書きされます。
     * @summary ユーザー辞書をインポートする
     * @param {boolean} override 重複したエントリがあった場合、上書きするかどうか
     * @param {{ [key: string]: ResponseGetUserDictWordsUserDictGet; }} requestBody 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    importUserDictWordsRaw(requestParameters: ImportUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 指定されたユーザー辞書をインポートします。<br> 従来の API と互換性のある `UserDictWordForCompat` と、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` の両方の型に対応しています。<br> `?override=true` を指定すると、UUID が重複したエントリはインポートしたデータで上書きされます。
     * ユーザー辞書をインポートする
     */
    importUserDictWords(requestParameters: ImportUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルをロードします。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * @summary 指定されたスタイル ID に紐づく音声合成モデルをロードする
     * @param {number} speaker 
     * @param {boolean} [skipReinit] 既にロード済みの音声合成モデルの再ロードをスキップするかどうか
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    initializeSpeakerRaw(requestParameters: InitializeSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルをロードします。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定されたスタイル ID に紐づく音声合成モデルをロードする
     */
    initializeSpeaker(requestParameters: InitializeSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 音声合成モデルをインストールします。<br> ファイルからインストールする場合は `file` を指定してください。<br> URL からインストールする場合は `url` を指定してください。
     * @summary 音声合成モデルをインストールする
     * @param {Blob} [file] 
     * @param {string} [url] 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    installModelRaw(requestParameters: InstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 音声合成モデルをインストールします。<br> ファイルからインストールする場合は `file` を指定してください。<br> URL からインストールする場合は `url` を指定してください。
     * 音声合成モデルをインストールする
     */
    installModel(requestParameters: InstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかどうかを返します。
     * @summary 指定されたスタイル ID に紐づく音声合成モデルがロードされているかを確認する
     * @param {number} speaker 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    isInitializedSpeakerRaw(requestParameters: IsInitializedSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<boolean>>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかどうかを返します。
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかを確認する
     */
    isInitializedSpeaker(requestParameters: IsInitializedSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<boolean>;

    /**
     * 指定された音声合成モデルをロードします。すでにロード済みの場合は何も行われません。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * @summary 指定された音声合成モデルをロードする
     * @param {string} aivmUuid 音声合成モデルの UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    loadModelRaw(requestParameters: LoadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 指定された音声合成モデルをロードします。すでにロード済みの場合は何も行われません。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定された音声合成モデルをロードする
     */
    loadModel(requestParameters: LoadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 
     * @summary アクセント句から音高・音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     * @param {number} speaker 
     * @param {Array<AccentPhrase>} accentPhrase 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    moraDataRaw(requestParameters: MoraDataRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>>;

    /**
     * アクセント句から音高・音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    moraData(requestParameters: MoraDataRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>>;

    /**
     * 
     * @summary アクセント句から音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     * @param {number} speaker 
     * @param {Array<AccentPhrase>} accentPhrase 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    moraLengthRaw(requestParameters: MoraLengthRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>>;

    /**
     * アクセント句から音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    moraLength(requestParameters: MoraLengthRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>>;

    /**
     * 
     * @summary アクセント句から音高を得る (AivisSpeech Engine では常にダミーの値が返されます)
     * @param {number} speaker 
     * @param {Array<AccentPhrase>} accentPhrase 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    moraPitchRaw(requestParameters: MoraPitchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>>;

    /**
     * アクセント句から音高を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    moraPitch(requestParameters: MoraPitchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>>;

    /**
     * 指定されたベーススタイルに対してエンジン内の各キャラクターがモーフィング機能を利用可能か返します。<br> モーフィングの許可/禁止は `/speakers `の `speaker.supported_features.synthesis_morphing` に記載されています。<br> プロパティが存在しない場合は、モーフィングが許可されているとみなします。<br> 返り値のスタイル ID は string 型なので注意。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 全ての話者でモーフィングが禁止されています。
     * @summary 指定したスタイルに対してエンジン内のキャラクターがモーフィングが可能か判定する
     * @param {Array<number>} requestBody 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    morphableTargetsRaw(requestParameters: MorphableTargetsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<{ [key: string]: MorphableTargetInfo; }>>>;

    /**
     * 指定されたベーススタイルに対してエンジン内の各キャラクターがモーフィング機能を利用可能か返します。<br> モーフィングの許可/禁止は `/speakers `の `speaker.supported_features.synthesis_morphing` に記載されています。<br> プロパティが存在しない場合は、モーフィングが許可されているとみなします。<br> 返り値のスタイル ID は string 型なので注意。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 全ての話者でモーフィングが禁止されています。
     * 指定したスタイルに対してエンジン内のキャラクターがモーフィングが可能か判定する
     */
    morphableTargets(requestParameters: MorphableTargetsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<{ [key: string]: MorphableTargetInfo; }>>;

    /**
     * 
     * @summary 複数まとめて音声合成する
     * @param {number} speaker 
     * @param {Array<AudioQuery>} audioQuery 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    multiSynthesisRaw(requestParameters: MultiSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * 複数まとめて音声合成する
     */
    multiSynthesis(requestParameters: MultiSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * 設定ページを返します。
     * @summary Setting Get
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    settingGetRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 設定ページを返します。
     * Setting Get
     */
    settingGet(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 設定を更新します。
     * @summary Setting Post
     * @param {CorsPolicyMode} corsPolicyMode 
     * @param {string} [allowOrigin] 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    settingPostRaw(requestParameters: SettingPostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 設定を更新します。
     * Setting Post
     */
    settingPost(requestParameters: SettingPostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {number} speaker 
     * @param {Score} score 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    singFrameAudioQueryRaw(requestParameters: SingFrameAudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<FrameAudioQuery>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    singFrameAudioQuery(requestParameters: SingFrameAudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<FrameAudioQuery>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {number} speaker 
     * @param {BodySingFrameF0SingFrameF0Post} bodySingFrameF0SingFrameF0Post 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    singFrameF0Raw(requestParameters: SingFrameF0Request, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<number>>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    singFrameF0(requestParameters: SingFrameF0Request, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<number>>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {number} speaker 
     * @param {BodySingFrameVolumeSingFrameVolumePost} bodySingFrameVolumeSingFrameVolumePost 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    singFrameVolumeRaw(requestParameters: SingFrameVolumeRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<number>>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    singFrameVolume(requestParameters: SingFrameVolumeRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<number>>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {string} speakerUuid 
     * @param {'base64' | 'url'} [resourceFormat] 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    singerInfoRaw(requestParameters: SingerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SpeakerInfo>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    singerInfo(requestParameters: SingerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SpeakerInfo>;

    /**
     * 
     * @summary AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    singersRaw(requestParameters: SingersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Speaker>>>;

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    singers(requestParameters: SingersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Speaker>>;

    /**
     * UUID で指定された話者の情報を返します。 画像や音声は resource_format で指定した形式で返されます。
     * @summary UUID で指定された話者の情報を取得する
     * @param {string} speakerUuid 
     * @param {'base64' | 'url'} [resourceFormat] 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    speakerInfoRaw(requestParameters: SpeakerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SpeakerInfo>>;

    /**
     * UUID で指定された話者の情報を返します。 画像や音声は resource_format で指定した形式で返されます。
     * UUID で指定された話者の情報を取得する
     */
    speakerInfo(requestParameters: SpeakerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SpeakerInfo>;

    /**
     * 話者情報の一覧を返します。
     * @summary 話者情報の一覧を取得する
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    speakersRaw(requestParameters: SpeakersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Speaker>>>;

    /**
     * 話者情報の一覧を返します。
     * 話者情報の一覧を取得する
     */
    speakers(requestParameters: SpeakersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Speaker>>;

    /**
     * このビルドでサポートされている、音声合成モデルの推論デバイスを返します。<br> 通常、下記の値が返されます。true であっても実際に推論デバイスが利用可能とは限りません。 - Windows: `{\"cpu\": true, \"cuda\": false, \"dml\": true}` - macOS: `{\"cpu\": true, \"cuda\": false, \"dml\": false}` - Linux: `{\"cpu\": true, \"cuda\": true, \"dml\": false}`
     * @summary このビルドでサポートされている、音声合成モデルの推論デバイスを取得する
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    supportedDevicesRaw(requestParameters: SupportedDevicesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SupportedDevicesInfo>>;

    /**
     * このビルドでサポートされている、音声合成モデルの推論デバイスを返します。<br> 通常、下記の値が返されます。true であっても実際に推論デバイスが利用可能とは限りません。 - Windows: `{\"cpu\": true, \"cuda\": false, \"dml\": true}` - macOS: `{\"cpu\": true, \"cuda\": false, \"dml\": false}` - Linux: `{\"cpu\": true, \"cuda\": true, \"dml\": false}`
     * このビルドでサポートされている、音声合成モデルの推論デバイスを取得する
     */
    supportedDevices(requestParameters: SupportedDevicesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SupportedDevicesInfo>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルを用いて音声合成を行います。
     * @summary 音声合成する
     * @param {number} speaker 
     * @param {AudioQuery} audioQuery 
     * @param {boolean} [enableInterrogativeUpspeak] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    synthesisRaw(requestParameters: SynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルを用いて音声合成を行います。
     * 音声合成する
     */
    synthesis(requestParameters: SynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * 指定された 2 種類のスタイルで音声を合成、指定した割合でモーフィングした音声を得ます。<br> モーフィングの割合は `morph_rate` で指定でき、0.0 でベースのスタイル、1.0 でターゲットのスタイルに近づきます。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 常に 400 Bad Request を返します。
     * @summary 2種類のスタイルでモーフィングした音声を合成する
     * @param {number} baseSpeaker 
     * @param {number} targetSpeaker 
     * @param {number} morphRate 
     * @param {AudioQuery} audioQuery 
     * @param {string} [coreVersion] AivisSpeech Engine ではサポートされていないパラメータです (常に無視されます) 。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    synthesisMorphingRaw(requestParameters: SynthesisMorphingRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>>;

    /**
     * 指定された 2 種類のスタイルで音声を合成、指定した割合でモーフィングした音声を得ます。<br> モーフィングの割合は `morph_rate` で指定でき、0.0 でベースのスタイル、1.0 でターゲットのスタイルに近づきます。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 常に 400 Bad Request を返します。
     * 2種類のスタイルでモーフィングした音声を合成する
     */
    synthesisMorphing(requestParameters: SynthesisMorphingRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob>;

    /**
     * 指定された音声合成モデルをアンインストールします。
     * @summary 指定された音声合成モデルをアンインストールする
     * @param {string} aivmUuid 音声合成モデルの UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    uninstallModelRaw(requestParameters: UninstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 指定された音声合成モデルをアンインストールします。
     * 指定された音声合成モデルをアンインストールする
     */
    uninstallModel(requestParameters: UninstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 指定された音声合成モデルをアンロードします。
     * @summary 指定された音声合成モデルをアンロードする
     * @param {string} aivmUuid 音声合成モデルの UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    unloadModelRaw(requestParameters: UnloadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * 指定された音声合成モデルをアンロードします。
     * 指定された音声合成モデルをアンロードする
     */
    unloadModel(requestParameters: UnloadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * AivisHub から指定された音声合成モデルの一番新しいバージョンをダウンロードし、 インストール済みの音声合成モデルへ上書き更新します。
     * @summary 指定された音声合成モデルを更新する
     * @param {string} aivmUuid 音声合成モデルの UUID
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    updateModelRaw(requestParameters: UpdateModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * AivisHub から指定された音声合成モデルの一番新しいバージョンをダウンロードし、 インストール済みの音声合成モデルへ上書き更新します。
     * 指定された音声合成モデルを更新する
     */
    updateModel(requestParameters: UpdateModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * 既存のプリセットを更新します。
     * @summary 既存のプリセットを更新する
     * @param {Preset} preset 
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    updatePresetRaw(requestParameters: UpdatePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<number>>;

    /**
     * 既存のプリセットを更新します。
     * 既存のプリセットを更新する
     */
    updatePreset(requestParameters: UpdatePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<number>;

    /**
     * ユーザー辞書に登録されている単語を更新します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * @summary ユーザー辞書に登録されている単語を更新する
     * @param {string} wordUuid 更新する単語の UUID
     * @param {Array<string>} surface 単語の表層形
     * @param {Array<string>} pronunciation 単語の発音（カタカナ）
     * @param {Array<number>} accentType 東京式アクセントにおけるアクセント型&lt;br&gt;音高が下がる直前のモーラのインデックスを 1-indexed で指定します。0 は平板型を意味します。&lt;br&gt;例として、&#x60;surface: [\&quot;新田\&quot;, \&quot;真剣佑\&quot;], pronunciation: [\&quot;あらた\&quot;, \&quot;まっけんゆう\&quot;]&#x60; のとき、&#x60;accent_type: [1, 3]&#x60; (新田 → 頭高型, 真剣佑 → 中高型) のように指定します。
     * @param {WordTypes} [wordType] 単語の品詞&lt;br&gt;固有名詞 / 地名 / 組織・施設名 / 人名 / 人名 (姓) / 人名 (名) / 普通名詞 / 動詞 / 形容詞 / 語尾 のいずれかを指定します。&lt;br&gt;未指定時は &#x60;固有名詞&#x60; が設定されます。
     * @param {number} [priority] 単語の優先度 (1~9 の範囲を推奨)&lt;br&gt;数値が大きいほど、辞書適用時に優先して利用されます。&lt;br&gt;未指定時は &#x60;5&#x60; が設定されます。
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    updateUserDictWordRaw(requestParameters: UpdateUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>>;

    /**
     * ユーザー辞書に登録されている単語を更新します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に登録されている単語を更新する
     */
    updateUserDictWord(requestParameters: UpdateUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void>;

    /**
     * テキストが AquesTalk 風記法に従っているかどうかを判定します。従っていない場合はエラーが返ります。
     * @summary テキストが AquesTalk 風記法に従っているか判定する
     * @param {string} text 判定する対象の文字列
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    validateKanaRaw(requestParameters: ValidateKanaRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<boolean>>;

    /**
     * テキストが AquesTalk 風記法に従っているかどうかを判定します。従っていない場合はエラーが返ります。
     * テキストが AquesTalk 風記法に従っているか判定する
     */
    validateKana(requestParameters: ValidateKanaRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<boolean>;

    /**
     * エンジンのバージョンを取得します。
     * @summary Version
     * @param {*} [options] Override http request option.
     * @throws {RequiredError}
     * @memberof DefaultApiInterface
     */
    versionRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>>;

    /**
     * エンジンのバージョンを取得します。
     * Version
     */
    version(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string>;

}

/**
 * 
 */
export class DefaultApi extends runtime.BaseAPI implements DefaultApiInterface {

    /**
     * テキストからアクセント句を得ます。<br> is_kanaが`true`のとき、テキストは次の AquesTalk 風記法で解釈されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。 * アクセント句末に`？`(全角)を入れることにより疑問文の発音ができる。
     * テキストからアクセント句を得る
     */
    async accentPhrasesRaw(requestParameters: AccentPhrasesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling accentPhrases.');
        }

        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling accentPhrases.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.isKana !== undefined) {
            queryParameters['is_kana'] = requestParameters.isKana;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/accent_phrases`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * テキストからアクセント句を得ます。<br> is_kanaが`true`のとき、テキストは次の AquesTalk 風記法で解釈されます。デフォルトは`false`です。 * 全てのカナはカタカナで記述される * アクセント句は`/`または`、`で区切る。`、`で区切った場合に限り無音区間が挿入される。 * カナの手前に`_`を入れるとそのカナは無声化される * アクセント位置を`\'`で指定する。全てのアクセント句にはアクセント位置を1つ指定する必要がある。 * アクセント句末に`？`(全角)を入れることにより疑問文の発音ができる。
     * テキストからアクセント句を得る
     */
    async accentPhrases(requestParameters: AccentPhrasesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>> {
        const response = await this.accentPhrasesRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 新しいプリセットを追加します。
     * 新しいプリセットを追加する
     */
    async addPresetRaw(requestParameters: AddPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<number>> {
        if (requestParameters.preset === null || requestParameters.preset === undefined) {
            throw new runtime.RequiredError('preset','Required parameter requestParameters.preset was null or undefined when calling addPreset.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/add_preset`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: PresetToJSON(requestParameters.preset),
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<number>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * 新しいプリセットを追加します。
     * 新しいプリセットを追加する
     */
    async addPreset(requestParameters: AddPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<number> {
        const response = await this.addPresetRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * ユーザー辞書に単語を追加します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に単語を追加する
     */
    async addUserDictWordRaw(requestParameters: AddUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>> {
        if (requestParameters.surface === null || requestParameters.surface === undefined) {
            throw new runtime.RequiredError('surface','Required parameter requestParameters.surface was null or undefined when calling addUserDictWord.');
        }

        if (requestParameters.pronunciation === null || requestParameters.pronunciation === undefined) {
            throw new runtime.RequiredError('pronunciation','Required parameter requestParameters.pronunciation was null or undefined when calling addUserDictWord.');
        }

        if (requestParameters.accentType === null || requestParameters.accentType === undefined) {
            throw new runtime.RequiredError('accentType','Required parameter requestParameters.accentType was null or undefined when calling addUserDictWord.');
        }

        const queryParameters: any = {};

        if (requestParameters.surface) {
            queryParameters['surface'] = requestParameters.surface;
        }

        if (requestParameters.pronunciation) {
            queryParameters['pronunciation'] = requestParameters.pronunciation;
        }

        if (requestParameters.accentType) {
            queryParameters['accent_type'] = requestParameters.accentType;
        }

        if (requestParameters.wordType !== undefined) {
            queryParameters['word_type'] = requestParameters.wordType;
        }

        if (requestParameters.priority !== undefined) {
            queryParameters['priority'] = requestParameters.priority;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/user_dict_word`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<string>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * ユーザー辞書に単語を追加します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に単語を追加する
     */
    async addUserDictWord(requestParameters: AddUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string> {
        const response = await this.addUserDictWordRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリを作成する
     */
    async audioQueryRaw(requestParameters: AudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AudioQuery>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling audioQuery.');
        }

        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling audioQuery.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/audio_query`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => AudioQueryFromJSON(jsonValue));
    }

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリを作成する
     */
    async audioQuery(requestParameters: AudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AudioQuery> {
        const response = await this.audioQueryRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリをプリセットを用いて作成する
     */
    async audioQueryFromPresetRaw(requestParameters: AudioQueryFromPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AudioQuery>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling audioQueryFromPreset.');
        }

        if (requestParameters.presetId === null || requestParameters.presetId === undefined) {
            throw new runtime.RequiredError('presetId','Required parameter requestParameters.presetId was null or undefined when calling audioQueryFromPreset.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        if (requestParameters.presetId !== undefined) {
            queryParameters['preset_id'] = requestParameters.presetId;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/audio_query_from_preset`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => AudioQueryFromJSON(jsonValue));
    }

    /**
     * 音声合成用のクエリの初期値を得ます。ここで得られたクエリはそのまま音声合成に利用できます。<br> 各値の意味は `Schemas` を参照してください。
     * 音声合成用のクエリをプリセットを用いて作成する
     */
    async audioQueryFromPreset(requestParameters: AudioQueryFromPresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AudioQuery> {
        const response = await this.audioQueryFromPresetRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async cancellableSynthesisRaw(requestParameters: CancellableSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling cancellableSynthesis.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling cancellableSynthesis.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/cancellable_synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: AudioQueryToJSON(requestParameters.audioQuery),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async cancellableSynthesis(requestParameters: CancellableSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.cancellableSynthesisRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * Base64 エンコードされた WAV データを一つに結合し、WAV ファイルで返します。
     * Base64 エンコードされた複数の WAV データを一つに結合する
     */
    async connectWavesRaw(requestParameters: ConnectWavesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling connectWaves.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/connect_waves`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * Base64 エンコードされた WAV データを一つに結合し、WAV ファイルで返します。
     * Base64 エンコードされた複数の WAV データを一つに結合する
     */
    async connectWaves(requestParameters: ConnectWavesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.connectWavesRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 利用可能なコアのバージョン一覧を取得します。
     * Core Versions
     */
    async coreVersionsRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<string>>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/core_versions`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse<any>(response);
    }

    /**
     * 利用可能なコアのバージョン一覧を取得します。
     * Core Versions
     */
    async coreVersions(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<string>> {
        const response = await this.coreVersionsRaw(initOverrides);
        return await response.value();
    }

    /**
     * 既存のプリセットを削除します。
     * 既存のプリセットを削除する
     */
    async deletePresetRaw(requestParameters: DeletePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.id === null || requestParameters.id === undefined) {
            throw new runtime.RequiredError('id','Required parameter requestParameters.id was null or undefined when calling deletePreset.');
        }

        const queryParameters: any = {};

        if (requestParameters.id !== undefined) {
            queryParameters['id'] = requestParameters.id;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/delete_preset`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 既存のプリセットを削除します。
     * 既存のプリセットを削除する
     */
    async deletePreset(requestParameters: DeletePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.deletePresetRaw(requestParameters, initOverrides);
    }

    /**
     * ユーザー辞書に登録されている単語を削除します。
     * ユーザー辞書に登録されている単語を削除する
     */
    async deleteUserDictWordRaw(requestParameters: DeleteUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.wordUuid === null || requestParameters.wordUuid === undefined) {
            throw new runtime.RequiredError('wordUuid','Required parameter requestParameters.wordUuid was null or undefined when calling deleteUserDictWord.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/user_dict_word/{word_uuid}`.replace(`{${"word_uuid"}}`, encodeURIComponent(String(requestParameters.wordUuid))),
            method: 'DELETE',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * ユーザー辞書に登録されている単語を削除します。
     * ユーザー辞書に登録されている単語を削除する
     */
    async deleteUserDictWord(requestParameters: DeleteUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.deleteUserDictWordRaw(requestParameters, initOverrides);
    }

    /**
     * エンジンマニフェストを取得します。
     * Engine Manifest
     */
    async engineManifestRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<EngineManifest>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/engine_manifest`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => EngineManifestFromJSON(jsonValue));
    }

    /**
     * エンジンマニフェストを取得します。
     * Engine Manifest
     */
    async engineManifest(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<EngineManifest> {
        const response = await this.engineManifestRaw(initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async frameSynthesisRaw(requestParameters: FrameSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling frameSynthesis.');
        }

        if (requestParameters.frameAudioQuery === null || requestParameters.frameAudioQuery === undefined) {
            throw new runtime.RequiredError('frameAudioQuery','Required parameter requestParameters.frameAudioQuery was null or undefined when calling frameSynthesis.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/frame_synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: FrameAudioQueryToJSON(requestParameters.frameAudioQuery),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async frameSynthesis(requestParameters: FrameSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.frameSynthesisRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定された音声合成モデルの情報を取得します。
     * 指定された音声合成モデルの情報を取得する
     */
    async getAivmInfoRaw(requestParameters: GetAivmInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<AivmInfo>> {
        if (requestParameters.aivmUuid === null || requestParameters.aivmUuid === undefined) {
            throw new runtime.RequiredError('aivmUuid','Required parameter requestParameters.aivmUuid was null or undefined when calling getAivmInfo.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models/{aivm_uuid}`.replace(`{${"aivm_uuid"}}`, encodeURIComponent(String(requestParameters.aivmUuid))),
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => AivmInfoFromJSON(jsonValue));
    }

    /**
     * 指定された音声合成モデルの情報を取得します。
     * 指定された音声合成モデルの情報を取得する
     */
    async getAivmInfo(requestParameters: GetAivmInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<AivmInfo> {
        const response = await this.getAivmInfoRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * インストール済みのすべての音声合成モデルの情報を返します。
     * インストール済みのすべての音声合成モデルの情報を取得する
     */
    async getInstalledAivmInfosRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<{ [key: string]: AivmInfo; }>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => runtime.mapValues(jsonValue, AivmInfoFromJSON));
    }

    /**
     * インストール済みのすべての音声合成モデルの情報を返します。
     * インストール済みのすべての音声合成モデルの情報を取得する
     */
    async getInstalledAivmInfos(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<{ [key: string]: AivmInfo; }> {
        const response = await this.getInstalledAivmInfosRaw(initOverrides);
        return await response.value();
    }

    /**
     * ポータルページを返します。
     * Get Portal Page
     */
    async getPortalPageRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<string>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * ポータルページを返します。
     * Get Portal Page
     */
    async getPortalPage(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string> {
        const response = await this.getPortalPageRaw(initOverrides);
        return await response.value();
    }

    /**
     * エンジンが保持しているプリセットの設定を返します。
     * エンジンが保持しているプリセットの設定を取得する
     */
    async getPresetsRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Preset>>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/presets`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(PresetFromJSON));
    }

    /**
     * エンジンが保持しているプリセットの設定を返します。
     * エンジンが保持しているプリセットの設定を取得する
     */
    async getPresets(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Preset>> {
        const response = await this.getPresetsRaw(initOverrides);
        return await response.value();
    }

    /**
     * ユーザー辞書に登録されている単語の一覧を返します。<br> 複合語アクセントのサポートを有効にするか次第で、返されるデータ型が変化します。<br> デフォルトでは、従来の API と互換性のある `UserDictWordForCompat` を返します。<br> `?enable_compound_accent=true` を指定すると、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` を返します。
     * ユーザー辞書に登録されている単語の一覧を取得する
     */
    async getUserDictWordsRaw(requestParameters: GetUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<{ [key: string]: ResponseGetUserDictWordsUserDictGet; }>> {
        const queryParameters: any = {};

        if (requestParameters.enableCompoundAccent !== undefined) {
            queryParameters['enable_compound_accent'] = requestParameters.enableCompoundAccent;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/user_dict`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => runtime.mapValues(jsonValue, ResponseGetUserDictWordsUserDictGetFromJSON));
    }

    /**
     * ユーザー辞書に登録されている単語の一覧を返します。<br> 複合語アクセントのサポートを有効にするか次第で、返されるデータ型が変化します。<br> デフォルトでは、従来の API と互換性のある `UserDictWordForCompat` を返します。<br> `?enable_compound_accent=true` を指定すると、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` を返します。
     * ユーザー辞書に登録されている単語の一覧を取得する
     */
    async getUserDictWords(requestParameters: GetUserDictWordsRequest = {}, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<{ [key: string]: ResponseGetUserDictWordsUserDictGet; }> {
        const response = await this.getUserDictWordsRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定されたユーザー辞書をインポートします。<br> 従来の API と互換性のある `UserDictWordForCompat` と、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` の両方の型に対応しています。<br> `?override=true` を指定すると、UUID が重複したエントリはインポートしたデータで上書きされます。
     * ユーザー辞書をインポートする
     */
    async importUserDictWordsRaw(requestParameters: ImportUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.override === null || requestParameters.override === undefined) {
            throw new runtime.RequiredError('override','Required parameter requestParameters.override was null or undefined when calling importUserDictWords.');
        }

        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling importUserDictWords.');
        }

        const queryParameters: any = {};

        if (requestParameters.override !== undefined) {
            queryParameters['override'] = requestParameters.override;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/import_user_dict`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 指定されたユーザー辞書をインポートします。<br> 従来の API と互換性のある `UserDictWordForCompat` と、AivisSpeech Engine 1.1.0 以降で利用可能な `UserDictWord` の両方の型に対応しています。<br> `?override=true` を指定すると、UUID が重複したエントリはインポートしたデータで上書きされます。
     * ユーザー辞書をインポートする
     */
    async importUserDictWords(requestParameters: ImportUserDictWordsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.importUserDictWordsRaw(requestParameters, initOverrides);
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルをロードします。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定されたスタイル ID に紐づく音声合成モデルをロードする
     */
    async initializeSpeakerRaw(requestParameters: InitializeSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling initializeSpeaker.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.skipReinit !== undefined) {
            queryParameters['skip_reinit'] = requestParameters.skipReinit;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/initialize_speaker`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルをロードします。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定されたスタイル ID に紐づく音声合成モデルをロードする
     */
    async initializeSpeaker(requestParameters: InitializeSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.initializeSpeakerRaw(requestParameters, initOverrides);
    }

    /**
     * 音声合成モデルをインストールします。<br> ファイルからインストールする場合は `file` を指定してください。<br> URL からインストールする場合は `url` を指定してください。
     * 音声合成モデルをインストールする
     */
    async installModelRaw(requestParameters: InstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const consumes: runtime.Consume[] = [
            { contentType: 'multipart/form-data' },
        ];
        // @ts-ignore: canConsumeForm may be unused
        const canConsumeForm = runtime.canConsumeForm(consumes);

        let formParams: { append(param: string, value: any): any };
        let useForm = false;
        // use FormData to transmit files using content-type "multipart/form-data"
        useForm = canConsumeForm;
        if (useForm) {
            formParams = new FormData();
        } else {
            formParams = new URLSearchParams();
        }

        if (requestParameters.file !== undefined) {
            formParams.append('file', requestParameters.file as any);
        }

        if (requestParameters.url !== undefined) {
            formParams.append('url', requestParameters.url as any);
        }

        const response = await this.request({
            path: `/aivm_models/install`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: formParams,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 音声合成モデルをインストールします。<br> ファイルからインストールする場合は `file` を指定してください。<br> URL からインストールする場合は `url` を指定してください。
     * 音声合成モデルをインストールする
     */
    async installModel(requestParameters: InstallModelRequest = {}, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.installModelRaw(requestParameters, initOverrides);
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかどうかを返します。
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかを確認する
     */
    async isInitializedSpeakerRaw(requestParameters: IsInitializedSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<boolean>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling isInitializedSpeaker.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/is_initialized_speaker`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<boolean>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかどうかを返します。
     * 指定されたスタイル ID に紐づく音声合成モデルがロードされているかを確認する
     */
    async isInitializedSpeaker(requestParameters: IsInitializedSpeakerRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<boolean> {
        const response = await this.isInitializedSpeakerRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定された音声合成モデルをロードします。すでにロード済みの場合は何も行われません。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定された音声合成モデルをロードする
     */
    async loadModelRaw(requestParameters: LoadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.aivmUuid === null || requestParameters.aivmUuid === undefined) {
            throw new runtime.RequiredError('aivmUuid','Required parameter requestParameters.aivmUuid was null or undefined when calling loadModel.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models/{aivm_uuid}/load`.replace(`{${"aivm_uuid"}}`, encodeURIComponent(String(requestParameters.aivmUuid))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 指定された音声合成モデルをロードします。すでにロード済みの場合は何も行われません。<br> 実行しなくても他の API は利用できますが、音声合成の初回実行時に時間がかかることがあります。
     * 指定された音声合成モデルをロードする
     */
    async loadModel(requestParameters: LoadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.loadModelRaw(requestParameters, initOverrides);
    }

    /**
     * アクセント句から音高・音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraDataRaw(requestParameters: MoraDataRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraData.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraData.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_data`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音高・音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraData(requestParameters: MoraDataRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>> {
        const response = await this.moraDataRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * アクセント句から音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraLengthRaw(requestParameters: MoraLengthRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraLength.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraLength.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_length`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音素長を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraLength(requestParameters: MoraLengthRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>> {
        const response = await this.moraLengthRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * アクセント句から音高を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraPitchRaw(requestParameters: MoraPitchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<AccentPhrase>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling moraPitch.');
        }

        if (requestParameters.accentPhrase === null || requestParameters.accentPhrase === undefined) {
            throw new runtime.RequiredError('accentPhrase','Required parameter requestParameters.accentPhrase was null or undefined when calling moraPitch.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/mora_pitch`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.accentPhrase.map(AccentPhraseToJSON),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(AccentPhraseFromJSON));
    }

    /**
     * アクセント句から音高を得る (AivisSpeech Engine では常にダミーの値が返されます)
     */
    async moraPitch(requestParameters: MoraPitchRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<AccentPhrase>> {
        const response = await this.moraPitchRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定されたベーススタイルに対してエンジン内の各キャラクターがモーフィング機能を利用可能か返します。<br> モーフィングの許可/禁止は `/speakers `の `speaker.supported_features.synthesis_morphing` に記載されています。<br> プロパティが存在しない場合は、モーフィングが許可されているとみなします。<br> 返り値のスタイル ID は string 型なので注意。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 全ての話者でモーフィングが禁止されています。
     * 指定したスタイルに対してエンジン内のキャラクターがモーフィングが可能か判定する
     */
    async morphableTargetsRaw(requestParameters: MorphableTargetsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<{ [key: string]: MorphableTargetInfo; }>>> {
        if (requestParameters.requestBody === null || requestParameters.requestBody === undefined) {
            throw new runtime.RequiredError('requestBody','Required parameter requestParameters.requestBody was null or undefined when calling morphableTargets.');
        }

        const queryParameters: any = {};

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/morphable_targets`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.requestBody,
        }, initOverrides);

        return new runtime.JSONApiResponse<any>(response);
    }

    /**
     * 指定されたベーススタイルに対してエンジン内の各キャラクターがモーフィング機能を利用可能か返します。<br> モーフィングの許可/禁止は `/speakers `の `speaker.supported_features.synthesis_morphing` に記載されています。<br> プロパティが存在しない場合は、モーフィングが許可されているとみなします。<br> 返り値のスタイル ID は string 型なので注意。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 全ての話者でモーフィングが禁止されています。
     * 指定したスタイルに対してエンジン内のキャラクターがモーフィングが可能か判定する
     */
    async morphableTargets(requestParameters: MorphableTargetsRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<{ [key: string]: MorphableTargetInfo; }>> {
        const response = await this.morphableTargetsRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 複数まとめて音声合成する
     */
    async multiSynthesisRaw(requestParameters: MultiSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling multiSynthesis.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling multiSynthesis.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/multi_synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: requestParameters.audioQuery.map(AudioQueryToJSON),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * 複数まとめて音声合成する
     */
    async multiSynthesis(requestParameters: MultiSynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.multiSynthesisRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 設定ページを返します。
     * Setting Get
     */
    async settingGetRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/setting`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 設定ページを返します。
     * Setting Get
     */
    async settingGet(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.settingGetRaw(initOverrides);
    }

    /**
     * 設定を更新します。
     * Setting Post
     */
    async settingPostRaw(requestParameters: SettingPostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.corsPolicyMode === null || requestParameters.corsPolicyMode === undefined) {
            throw new runtime.RequiredError('corsPolicyMode','Required parameter requestParameters.corsPolicyMode was null or undefined when calling settingPost.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const consumes: runtime.Consume[] = [
            { contentType: 'application/x-www-form-urlencoded' },
        ];
        // @ts-ignore: canConsumeForm may be unused
        const canConsumeForm = runtime.canConsumeForm(consumes);

        let formParams: { append(param: string, value: any): any };
        let useForm = false;
        if (useForm) {
            formParams = new FormData();
        } else {
            formParams = new URLSearchParams();
        }

        if (requestParameters.corsPolicyMode !== undefined) {
            formParams.append('cors_policy_mode', new Blob([JSON.stringify(CorsPolicyModeToJSON(requestParameters.corsPolicyMode))], { type: "application/json", }));
                    }

        if (requestParameters.allowOrigin !== undefined) {
            formParams.append('allow_origin', requestParameters.allowOrigin as any);
        }

        const response = await this.request({
            path: `/setting`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: formParams,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 設定を更新します。
     * Setting Post
     */
    async settingPost(requestParameters: SettingPostRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.settingPostRaw(requestParameters, initOverrides);
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameAudioQueryRaw(requestParameters: SingFrameAudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<FrameAudioQuery>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling singFrameAudioQuery.');
        }

        if (requestParameters.score === null || requestParameters.score === undefined) {
            throw new runtime.RequiredError('score','Required parameter requestParameters.score was null or undefined when calling singFrameAudioQuery.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/sing_frame_audio_query`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: ScoreToJSON(requestParameters.score),
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => FrameAudioQueryFromJSON(jsonValue));
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameAudioQuery(requestParameters: SingFrameAudioQueryRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<FrameAudioQuery> {
        const response = await this.singFrameAudioQueryRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameF0Raw(requestParameters: SingFrameF0Request, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<number>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling singFrameF0.');
        }

        if (requestParameters.bodySingFrameF0SingFrameF0Post === null || requestParameters.bodySingFrameF0SingFrameF0Post === undefined) {
            throw new runtime.RequiredError('bodySingFrameF0SingFrameF0Post','Required parameter requestParameters.bodySingFrameF0SingFrameF0Post was null or undefined when calling singFrameF0.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/sing_frame_f0`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: BodySingFrameF0SingFrameF0PostToJSON(requestParameters.bodySingFrameF0SingFrameF0Post),
        }, initOverrides);

        return new runtime.JSONApiResponse<any>(response);
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameF0(requestParameters: SingFrameF0Request, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<number>> {
        const response = await this.singFrameF0Raw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameVolumeRaw(requestParameters: SingFrameVolumeRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<number>>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling singFrameVolume.');
        }

        if (requestParameters.bodySingFrameVolumeSingFrameVolumePost === null || requestParameters.bodySingFrameVolumeSingFrameVolumePost === undefined) {
            throw new runtime.RequiredError('bodySingFrameVolumeSingFrameVolumePost','Required parameter requestParameters.bodySingFrameVolumeSingFrameVolumePost was null or undefined when calling singFrameVolume.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/sing_frame_volume`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: BodySingFrameVolumeSingFrameVolumePostToJSON(requestParameters.bodySingFrameVolumeSingFrameVolumePost),
        }, initOverrides);

        return new runtime.JSONApiResponse<any>(response);
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singFrameVolume(requestParameters: SingFrameVolumeRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<number>> {
        const response = await this.singFrameVolumeRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singerInfoRaw(requestParameters: SingerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SpeakerInfo>> {
        if (requestParameters.speakerUuid === null || requestParameters.speakerUuid === undefined) {
            throw new runtime.RequiredError('speakerUuid','Required parameter requestParameters.speakerUuid was null or undefined when calling singerInfo.');
        }

        const queryParameters: any = {};

        if (requestParameters.speakerUuid !== undefined) {
            queryParameters['speaker_uuid'] = requestParameters.speakerUuid;
        }

        if (requestParameters.resourceFormat !== undefined) {
            queryParameters['resource_format'] = requestParameters.resourceFormat;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/singer_info`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => SpeakerInfoFromJSON(jsonValue));
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singerInfo(requestParameters: SingerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SpeakerInfo> {
        const response = await this.singerInfoRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singersRaw(requestParameters: SingersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Speaker>>> {
        const queryParameters: any = {};

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/singers`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(SpeakerFromJSON));
    }

    /**
     * AivisSpeech Engine ではサポートされていない API です (常に 501 Not Implemented を返します)
     */
    async singers(requestParameters: SingersRequest = {}, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Speaker>> {
        const response = await this.singersRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * UUID で指定された話者の情報を返します。 画像や音声は resource_format で指定した形式で返されます。
     * UUID で指定された話者の情報を取得する
     */
    async speakerInfoRaw(requestParameters: SpeakerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SpeakerInfo>> {
        if (requestParameters.speakerUuid === null || requestParameters.speakerUuid === undefined) {
            throw new runtime.RequiredError('speakerUuid','Required parameter requestParameters.speakerUuid was null or undefined when calling speakerInfo.');
        }

        const queryParameters: any = {};

        if (requestParameters.speakerUuid !== undefined) {
            queryParameters['speaker_uuid'] = requestParameters.speakerUuid;
        }

        if (requestParameters.resourceFormat !== undefined) {
            queryParameters['resource_format'] = requestParameters.resourceFormat;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/speaker_info`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => SpeakerInfoFromJSON(jsonValue));
    }

    /**
     * UUID で指定された話者の情報を返します。 画像や音声は resource_format で指定した形式で返されます。
     * UUID で指定された話者の情報を取得する
     */
    async speakerInfo(requestParameters: SpeakerInfoRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SpeakerInfo> {
        const response = await this.speakerInfoRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 話者情報の一覧を返します。
     * 話者情報の一覧を取得する
     */
    async speakersRaw(requestParameters: SpeakersRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Array<Speaker>>> {
        const queryParameters: any = {};

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/speakers`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => jsonValue.map(SpeakerFromJSON));
    }

    /**
     * 話者情報の一覧を返します。
     * 話者情報の一覧を取得する
     */
    async speakers(requestParameters: SpeakersRequest = {}, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Array<Speaker>> {
        const response = await this.speakersRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * このビルドでサポートされている、音声合成モデルの推論デバイスを返します。<br> 通常、下記の値が返されます。true であっても実際に推論デバイスが利用可能とは限りません。 - Windows: `{\"cpu\": true, \"cuda\": false, \"dml\": true}` - macOS: `{\"cpu\": true, \"cuda\": false, \"dml\": false}` - Linux: `{\"cpu\": true, \"cuda\": true, \"dml\": false}`
     * このビルドでサポートされている、音声合成モデルの推論デバイスを取得する
     */
    async supportedDevicesRaw(requestParameters: SupportedDevicesRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<SupportedDevicesInfo>> {
        const queryParameters: any = {};

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/supported_devices`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.JSONApiResponse(response, (jsonValue) => SupportedDevicesInfoFromJSON(jsonValue));
    }

    /**
     * このビルドでサポートされている、音声合成モデルの推論デバイスを返します。<br> 通常、下記の値が返されます。true であっても実際に推論デバイスが利用可能とは限りません。 - Windows: `{\"cpu\": true, \"cuda\": false, \"dml\": true}` - macOS: `{\"cpu\": true, \"cuda\": false, \"dml\": false}` - Linux: `{\"cpu\": true, \"cuda\": true, \"dml\": false}`
     * このビルドでサポートされている、音声合成モデルの推論デバイスを取得する
     */
    async supportedDevices(requestParameters: SupportedDevicesRequest = {}, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<SupportedDevicesInfo> {
        const response = await this.supportedDevicesRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルを用いて音声合成を行います。
     * 音声合成する
     */
    async synthesisRaw(requestParameters: SynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.speaker === null || requestParameters.speaker === undefined) {
            throw new runtime.RequiredError('speaker','Required parameter requestParameters.speaker was null or undefined when calling synthesis.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling synthesis.');
        }

        const queryParameters: any = {};

        if (requestParameters.speaker !== undefined) {
            queryParameters['speaker'] = requestParameters.speaker;
        }

        if (requestParameters.enableInterrogativeUpspeak !== undefined) {
            queryParameters['enable_interrogative_upspeak'] = requestParameters.enableInterrogativeUpspeak;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/synthesis`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: AudioQueryToJSON(requestParameters.audioQuery),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * 指定されたスタイル ID に紐づく音声合成モデルを用いて音声合成を行います。
     * 音声合成する
     */
    async synthesis(requestParameters: SynthesisRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.synthesisRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定された 2 種類のスタイルで音声を合成、指定した割合でモーフィングした音声を得ます。<br> モーフィングの割合は `morph_rate` で指定でき、0.0 でベースのスタイル、1.0 でターゲットのスタイルに近づきます。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 常に 400 Bad Request を返します。
     * 2種類のスタイルでモーフィングした音声を合成する
     */
    async synthesisMorphingRaw(requestParameters: SynthesisMorphingRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<Blob>> {
        if (requestParameters.baseSpeaker === null || requestParameters.baseSpeaker === undefined) {
            throw new runtime.RequiredError('baseSpeaker','Required parameter requestParameters.baseSpeaker was null or undefined when calling synthesisMorphing.');
        }

        if (requestParameters.targetSpeaker === null || requestParameters.targetSpeaker === undefined) {
            throw new runtime.RequiredError('targetSpeaker','Required parameter requestParameters.targetSpeaker was null or undefined when calling synthesisMorphing.');
        }

        if (requestParameters.morphRate === null || requestParameters.morphRate === undefined) {
            throw new runtime.RequiredError('morphRate','Required parameter requestParameters.morphRate was null or undefined when calling synthesisMorphing.');
        }

        if (requestParameters.audioQuery === null || requestParameters.audioQuery === undefined) {
            throw new runtime.RequiredError('audioQuery','Required parameter requestParameters.audioQuery was null or undefined when calling synthesisMorphing.');
        }

        const queryParameters: any = {};

        if (requestParameters.baseSpeaker !== undefined) {
            queryParameters['base_speaker'] = requestParameters.baseSpeaker;
        }

        if (requestParameters.targetSpeaker !== undefined) {
            queryParameters['target_speaker'] = requestParameters.targetSpeaker;
        }

        if (requestParameters.morphRate !== undefined) {
            queryParameters['morph_rate'] = requestParameters.morphRate;
        }

        if (requestParameters.coreVersion !== undefined) {
            queryParameters['core_version'] = requestParameters.coreVersion;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/synthesis_morphing`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: AudioQueryToJSON(requestParameters.audioQuery),
        }, initOverrides);

        return new runtime.BlobApiResponse(response);
    }

    /**
     * 指定された 2 種類のスタイルで音声を合成、指定した割合でモーフィングした音声を得ます。<br> モーフィングの割合は `morph_rate` で指定でき、0.0 でベースのスタイル、1.0 でターゲットのスタイルに近づきます。<br> AivisSpeech Engine では話者ごとに発声タイミングが異なる関係で実装不可能なため (動作こそするが聴くに耐えない) 、 常に 400 Bad Request を返します。
     * 2種類のスタイルでモーフィングした音声を合成する
     */
    async synthesisMorphing(requestParameters: SynthesisMorphingRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<Blob> {
        const response = await this.synthesisMorphingRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * 指定された音声合成モデルをアンインストールします。
     * 指定された音声合成モデルをアンインストールする
     */
    async uninstallModelRaw(requestParameters: UninstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.aivmUuid === null || requestParameters.aivmUuid === undefined) {
            throw new runtime.RequiredError('aivmUuid','Required parameter requestParameters.aivmUuid was null or undefined when calling uninstallModel.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models/{aivm_uuid}/uninstall`.replace(`{${"aivm_uuid"}}`, encodeURIComponent(String(requestParameters.aivmUuid))),
            method: 'DELETE',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 指定された音声合成モデルをアンインストールします。
     * 指定された音声合成モデルをアンインストールする
     */
    async uninstallModel(requestParameters: UninstallModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.uninstallModelRaw(requestParameters, initOverrides);
    }

    /**
     * 指定された音声合成モデルをアンロードします。
     * 指定された音声合成モデルをアンロードする
     */
    async unloadModelRaw(requestParameters: UnloadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.aivmUuid === null || requestParameters.aivmUuid === undefined) {
            throw new runtime.RequiredError('aivmUuid','Required parameter requestParameters.aivmUuid was null or undefined when calling unloadModel.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models/{aivm_uuid}/unload`.replace(`{${"aivm_uuid"}}`, encodeURIComponent(String(requestParameters.aivmUuid))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * 指定された音声合成モデルをアンロードします。
     * 指定された音声合成モデルをアンロードする
     */
    async unloadModel(requestParameters: UnloadModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.unloadModelRaw(requestParameters, initOverrides);
    }

    /**
     * AivisHub から指定された音声合成モデルの一番新しいバージョンをダウンロードし、 インストール済みの音声合成モデルへ上書き更新します。
     * 指定された音声合成モデルを更新する
     */
    async updateModelRaw(requestParameters: UpdateModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.aivmUuid === null || requestParameters.aivmUuid === undefined) {
            throw new runtime.RequiredError('aivmUuid','Required parameter requestParameters.aivmUuid was null or undefined when calling updateModel.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/aivm_models/{aivm_uuid}/update`.replace(`{${"aivm_uuid"}}`, encodeURIComponent(String(requestParameters.aivmUuid))),
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * AivisHub から指定された音声合成モデルの一番新しいバージョンをダウンロードし、 インストール済みの音声合成モデルへ上書き更新します。
     * 指定された音声合成モデルを更新する
     */
    async updateModel(requestParameters: UpdateModelRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.updateModelRaw(requestParameters, initOverrides);
    }

    /**
     * 既存のプリセットを更新します。
     * 既存のプリセットを更新する
     */
    async updatePresetRaw(requestParameters: UpdatePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<number>> {
        if (requestParameters.preset === null || requestParameters.preset === undefined) {
            throw new runtime.RequiredError('preset','Required parameter requestParameters.preset was null or undefined when calling updatePreset.');
        }

        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        headerParameters['Content-Type'] = 'application/json';

        const response = await this.request({
            path: `/update_preset`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
            body: PresetToJSON(requestParameters.preset),
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<number>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * 既存のプリセットを更新します。
     * 既存のプリセットを更新する
     */
    async updatePreset(requestParameters: UpdatePresetRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<number> {
        const response = await this.updatePresetRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * ユーザー辞書に登録されている単語を更新します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に登録されている単語を更新する
     */
    async updateUserDictWordRaw(requestParameters: UpdateUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<void>> {
        if (requestParameters.wordUuid === null || requestParameters.wordUuid === undefined) {
            throw new runtime.RequiredError('wordUuid','Required parameter requestParameters.wordUuid was null or undefined when calling updateUserDictWord.');
        }

        if (requestParameters.surface === null || requestParameters.surface === undefined) {
            throw new runtime.RequiredError('surface','Required parameter requestParameters.surface was null or undefined when calling updateUserDictWord.');
        }

        if (requestParameters.pronunciation === null || requestParameters.pronunciation === undefined) {
            throw new runtime.RequiredError('pronunciation','Required parameter requestParameters.pronunciation was null or undefined when calling updateUserDictWord.');
        }

        if (requestParameters.accentType === null || requestParameters.accentType === undefined) {
            throw new runtime.RequiredError('accentType','Required parameter requestParameters.accentType was null or undefined when calling updateUserDictWord.');
        }

        const queryParameters: any = {};

        if (requestParameters.surface) {
            queryParameters['surface'] = requestParameters.surface;
        }

        if (requestParameters.pronunciation) {
            queryParameters['pronunciation'] = requestParameters.pronunciation;
        }

        if (requestParameters.accentType) {
            queryParameters['accent_type'] = requestParameters.accentType;
        }

        if (requestParameters.wordType !== undefined) {
            queryParameters['word_type'] = requestParameters.wordType;
        }

        if (requestParameters.priority !== undefined) {
            queryParameters['priority'] = requestParameters.priority;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/user_dict_word/{word_uuid}`.replace(`{${"word_uuid"}}`, encodeURIComponent(String(requestParameters.wordUuid))),
            method: 'PUT',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        return new runtime.VoidApiResponse(response);
    }

    /**
     * ユーザー辞書に登録されている単語を更新します。<br> 複合語を辞書に追加するには、`?surface=新田&surface=真剣佑&pronunciation=あらた&pronunciation=まっけんゆう&accent_type=1&accent_type=3` のように、`surface`, `pronunciation`, `accent_type` を同じ長さのリストで指定します。
     * ユーザー辞書に登録されている単語を更新する
     */
    async updateUserDictWord(requestParameters: UpdateUserDictWordRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<void> {
        await this.updateUserDictWordRaw(requestParameters, initOverrides);
    }

    /**
     * テキストが AquesTalk 風記法に従っているかどうかを判定します。従っていない場合はエラーが返ります。
     * テキストが AquesTalk 風記法に従っているか判定する
     */
    async validateKanaRaw(requestParameters: ValidateKanaRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<boolean>> {
        if (requestParameters.text === null || requestParameters.text === undefined) {
            throw new runtime.RequiredError('text','Required parameter requestParameters.text was null or undefined when calling validateKana.');
        }

        const queryParameters: any = {};

        if (requestParameters.text !== undefined) {
            queryParameters['text'] = requestParameters.text;
        }

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/validate_kana`,
            method: 'POST',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<boolean>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * テキストが AquesTalk 風記法に従っているかどうかを判定します。従っていない場合はエラーが返ります。
     * テキストが AquesTalk 風記法に従っているか判定する
     */
    async validateKana(requestParameters: ValidateKanaRequest, initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<boolean> {
        const response = await this.validateKanaRaw(requestParameters, initOverrides);
        return await response.value();
    }

    /**
     * エンジンのバージョンを取得します。
     * Version
     */
    async versionRaw(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<runtime.ApiResponse<string>> {
        const queryParameters: any = {};

        const headerParameters: runtime.HTTPHeaders = {};

        const response = await this.request({
            path: `/version`,
            method: 'GET',
            headers: headerParameters,
            query: queryParameters,
        }, initOverrides);

        if (this.isJsonMime(response.headers.get('content-type'))) {
            return new runtime.JSONApiResponse<string>(response);
        } else {
            return new runtime.TextApiResponse(response) as any;
        }
    }

    /**
     * エンジンのバージョンを取得します。
     * Version
     */
    async version(initOverrides?: RequestInit | runtime.InitOverrideFunction): Promise<string> {
        const response = await this.versionRaw(initOverrides);
        return await response.value();
    }

}

/**
 * @export
 */
export const SingerInfoResourceFormatEnum = {
    Base64: 'base64',
    Url: 'url'
} as const;
export type SingerInfoResourceFormatEnum = typeof SingerInfoResourceFormatEnum[keyof typeof SingerInfoResourceFormatEnum];
/**
 * @export
 */
export const SpeakerInfoResourceFormatEnum = {
    Base64: 'base64',
    Url: 'url'
} as const;
export type SpeakerInfoResourceFormatEnum = typeof SpeakerInfoResourceFormatEnum[keyof typeof SpeakerInfoResourceFormatEnum];
